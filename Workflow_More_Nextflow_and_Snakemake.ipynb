{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4601bc",
   "metadata": {},
   "source": [
    "<h1><center>Basic Bioinformatics Workflows on OSCAR: Snakemake and Nextflow</center></h1>\n",
    "<p><center>Instructors: Ashok Ragavendran and Jordan Lawson</center>\n",
    " <center>Center for Computation and Visualization</center>\n",
    " <center>Center for Computational Biology of Human Disease - Computational Biology Core</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfe5ec",
   "metadata": {},
   "source": [
    "Resources for help @brown <br> \n",
    "\n",
    "COBRE CBHD Computational Biology Core\n",
    "- Office hours\n",
    "- https://cbc.brown.edu\n",
    "- slack channel on ccv-share\n",
    "- cbc-help@brown.edu <br>\n",
    "\n",
    "Center for Computation and Visualization\n",
    "- Office hours\n",
    "- https://ccv.brown.edu\n",
    "- ccv-share slack channel\n",
    "- https://docs.ccv.brown.edu\n",
    "- support@ccv.brown.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2fc35",
   "metadata": {},
   "source": [
    "## What is Snakemake and Nextflow?  \n",
    "\n",
    "Snakemake and Nextflow are workflow management tools that allow users to easily write data-intensive computational **pipelines**. These pipelines, or workflows as they are also called, have the following key features:\n",
    "\n",
    "- Sequential processing of files\n",
    "- Usually requires more than one tool\n",
    "- Multiple programming languages\n",
    "- Most times each sample is processed individually\n",
    "- Compute resource intensive\n",
    "  - Alignment could take 16 cpus, 60 Gb RAM, 4-24 hours, 30Gb of disk space per sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6649f1",
   "metadata": {},
   "source": [
    "## Why do we care about these pipelines? \n",
    "\n",
    "### Reason 1: Reproducibility "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06abc40",
   "metadata": {},
   "source": [
    "<img src=\"./img/reproduce.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb742d3",
   "metadata": {},
   "source": [
    "The journal Nature published a survey that found that more than 70% of researchers have tried and failed to reproduce another scientist's experiments. This trend is hugely problematic because we then can't trust the findings from many studies enough to use them to make data-driven decisions. In short, we need tools and standards that help address the reproducibility crisis in science! \n",
    "\n",
    "Pipelines created with Snakemake and Nextflow incorporate version-control and state-of-the-art software tools, known as containers, to manage all software dependencies and create stable environments that can be trusted to reproduce analyses reliably and accurately. \n",
    "\n",
    "***Reproducibility is important for producing trustworthy research!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bbec0",
   "metadata": {},
   "source": [
    "### Reason 2: Portability\n",
    "\n",
    "#### What if we need to perform analyses with more resources?\n",
    "\n",
    "This type of scenario would require us to move our analyses to a different environment, for example, a High Performance Computing (HPC) cluster environment. \n",
    "\n",
    "An important feature of Snakemake and Nextflow workflow management tools is that they enable users to easily scale any pipeline written on a personal computer to then run on an HPC cluster such as OSCAR, the HPC cluster we use at Brown University. So now we can run our pipelines using high performance resources without having to change workflow definitions or hard-code a pipeline to a specific setup. As a result, **the code stays constant** across varying infrastructures, thereby allowing portability, easy collaboration, and avoiding lock-in. \n",
    "\n",
    "***In short, we can easily move our multi-step analyses (i.e., pipelines) to any place we need them!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d46b76",
   "metadata": {},
   "source": [
    "## So Let's See How All This Works! \n",
    "\n",
    "### Our Starting Point\n",
    "\n",
    "Say we have samples from reduced representation bisulfite sequencing (RRBS data) that we need to process on OSCAR by performing the following set of actions: \n",
    "\n",
    "<img src=\"./img/workflow.png\" width=\"700\"/>\n",
    "\n",
    "<h2><center>What do you do??</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadbe0a7",
   "metadata": {},
   "source": [
    "## A Naive Approach\n",
    "\n",
    "One solution would be to write a bunch of shell scripts that use various software tools to process the data in the ways we need. \n",
    "\n",
    "For example, if we need to run fastqc, trim galore, and then an alignment, we could just write a shell script for each step - so a total of 4 shell scripts in this case - where we have various inputs and outputs. This would look something as follows: \n",
    "\n",
    "**Script 1: Fastqc**\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH -t 48:00:00\n",
    "#SBATCH -n 32\n",
    "#SBATCH -J rrbs_fastqc\n",
    "#SBATCH --mem=198GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=jordan_lawson@brown.edu\n",
    "\n",
    "source /gpfs/runtime/cbc_conda/bin/activate_cbc_conda\n",
    "conda activate fedulov_rrbs\n",
    "for sample in `ls /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/Sequencing_Files/*fastq.gz`\n",
    "do\n",
    "align_dir=\"/gpfs/data/cbc/fedulov_alexey/porcine_rrbs\" \n",
    "fastqc -o ${align_dir}/fastqc $sample\n",
    "done\n",
    "```\n",
    "\n",
    "**Script 2: Trimming** \n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH -t 48:00:00\n",
    "#SBATCH -n 32\n",
    "#SBATCH -J trimmomatic_update\n",
    "#SBATCH --mem=198GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=jordan_lawson@brown.edu\n",
    "\n",
    "source /gpfs/runtime/cbc_conda/bin/activate_cbc_conda\n",
    "\n",
    "for sample in `ls /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/trim_galore/*_trimmed.fq.gz`\n",
    "do\n",
    "    dir=\"/gpfs/data/cbc/fedulov_alexey/porcine_rrbs/trimmomatic\"\n",
    "    base=$(basename $sample \"_trimmed.fq.gz\")\n",
    "    trimmomatic SE  -threads 8 -trimlog ${dir}/${base}_SE.log $sample ${dir}/${base}_tr.fq.gz ILLUMINACLIP:/gpfs/data/cbc/cbc_conda_v1/envs/cbc_conda/opt/trimmomatic-0.36/adapters/TruSeq3-SE.fa:2:30:5:6:true SLIDINGWINDOW:4:20 MINLEN:35\n",
    "done \n",
    "```\n",
    "\n",
    "\n",
    "**Script 3: Fastqc on trimmed reads**\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH -n 8\n",
    "#SBATCH -J retrim_fastqc_update\n",
    "#SBATCH --mem=16GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=jordan_lawson@brown.edu\n",
    "\n",
    "source /gpfs/runtime/cbc_conda/bin/activate_cbc_conda\n",
    "conda activate fedulov_rrbs\n",
    "for sample in `ls /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/trimmomatic/*_tr.fq.gz`\n",
    "do\n",
    "trim_qc_dir=\"/gpfs/data/cbc/fedulov_alexey/porcine_rrbs\"\n",
    "fastqc -o ${trim_qc_dir}/trimmomatic_qc $sample\n",
    "done\n",
    "```\n",
    "\n",
    "**Script 4: Alignment**\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 16\n",
    "#SBATCH -J bismark_align_update_redo\n",
    "#SBATCH --mem=160GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=jordan_lawson@brown.edu\n",
    "#SBATCH --array=1-18\n",
    "#SBATCH -e /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/logs/bismark_align_%a_%A_%j.err\n",
    "#SBATCH -o /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/logs/bismark_align_%a_%A_%j.out\n",
    "\n",
    "source /gpfs/runtime/cbc_conda/bin/activate_cbc_conda\n",
    "conda activate fedulov_rrbs\n",
    "input=($(ls /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/trimmomatic/*_tr.fq.gz)) # using the round brackets indicates that this is a bash array\n",
    "bismark -o /gpfs/data/cbc/fedulov_alexey/porcine_rrbs/alignments --bowtie2 --genome /gpfs/data/shared/databases/refchef_refs/S_scrofa/primary/bismark_index --un --pbat ${input[$((SLURM_ARRAY_TASK_ID -1))]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e5d964",
   "metadata": {},
   "source": [
    "## Problems with the Naive Approach \n",
    "\n",
    "Using multiple shell scripts to create a makeshift pipeline will work, but it is **inefficient**, can **get complicated fast**, and there are a few **challenges you have to manage**, such as: \n",
    "\n",
    "* Making sure you have the appropriate software and all dependencies for each step in the analysis - this can be a lot to stay on top of if you have a pipeline with a lot of steps! (imagine a 10 step process)\n",
    "* **Portability!** Building and running on different machines is much more work\n",
    "* Specifying where your output will go \n",
    "* Calling in the appropriate input (which is often the output from a previous step) \n",
    "* Handling where log files go \n",
    "* More labor intensive - we have to stay on top of jobs and monitor when each step finishes and then run next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb9e7b",
   "metadata": {},
   "source": [
    "## A Smarter Approach: Using Workflow Managers! \n",
    "\n",
    "The solution for processing your data in a much more efficient manner that handles the aforementioned issues is workflow management tools, such as Snakemake and Nextflow. Let's now learn how to use Snakemake and Nextflow..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325c7ef",
   "metadata": {},
   "source": [
    "## Next up.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372c107",
   "metadata": {},
   "source": [
    "<img src=\"./img/nextflow.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6872e2d",
   "metadata": {},
   "source": [
    "### Step 1: The Setup\n",
    "\n",
    "Let's first discuss setting up our environment on OSCAR so that we can get Snakemake up and running. \n",
    "\n",
    "**At this point, I am going to open my terminal on Open OnDemand (OOD) so that I can walk you through and show you how each of these steps and files below look. Feel free to open your terminal as well and follow along. To do so, you can go to OOD at https://ood.ccv.brown.edu and under the Clusters tab at the top select the >_OSCAR Shell Access option. All files used today can be found on GitHub in the folder at: https://github.com/compbiocore/workflows_on_OSCAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972493ea",
   "metadata": {},
   "source": [
    "#### Step 1a: Set up Nextflow Configuration Script using `compbiocore/workflows_on_OSCAR`:\n",
    "\n",
    "```bash\n",
    "[pcao5@node1322 ~]$ cd ~/\n",
    "[pcao5@node1322 ~]$ git clone https://github.com/compbiocore/workflows_on_OSCAR.git\n",
    "[pcao5@node1322 ~]$ git clone https://github.com/compbiocore/workflows_workshop.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bef35",
   "metadata": {},
   "source": [
    "#### Step 1b: Install `compbiocore/workflows_on_OSCAR` package:\n",
    "\n",
    "```bash\n",
    "bash ~/workflows_on_OSCAR/install_me/install.sh && source ~/.bashrc\n",
    "```\n",
    "\n",
    "\n",
    "For the 1st installation prompt, input `NextFlow`:\n",
    "\n",
    "```bash\n",
    "Welcome to a program designed to help you easily set up and run workflow management systems on OSCAR!\n",
    "\n",
    "Please type which software you wish to use: Nextflow or Snakemake? Nextflow\n",
    "```\n",
    "\n",
    "For the 2nd installation prompt, input your GitHub username (e.g., `paulcao-brown`):\n",
    "\n",
    "```bash\n",
    "Nextflow software detected, initializing configuration...\n",
    "What is your GitHub user name? paulcao-brown\n",
    "What is your GitHub token (we will keep this secret) - [Hit Enter when Done]?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2275fc4",
   "metadata": {},
   "source": [
    "#### Step 1c: Create a new GitHub Token and enter it:\n",
    "<img src=\"https://i.imgur.com/GBGDQhY.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b7e8b1",
   "metadata": {},
   "source": [
    "#### Step 1d: Complete the Installation \n",
    "\n",
    "\n",
    "```bash\n",
    "Currently the Nextflow default for HPC resources is: memory = 5.GB time = 2.h cpus = 2 \n",
    "Do you want to change these default resources for your Nextflow pipeline [Yes or No]? No\n",
    "Keeping defaults!\n",
    "\n",
    "OUTPUT MESSAGE:\n",
    "\n",
    "                ******************************************************************\n",
    "                 NEXTFLOW is now set up and configured and ready to run on OSCAR!\n",
    "                ******************************************************************\n",
    "                \n",
    "\n",
    "Your default resources for Nextflow are: memory = 5.GB time = 2.h cpus = 2 \n",
    "\n",
    "\n",
    "                To further customize your pipeline for efficiency, you can enter the following \n",
    "                label '<LabelName>' options right within processes in your Nextflow .nf script:\n",
    "                1. label 'OSCAR_small_job' (comes with memory = 4 GB, time = 1 hour, cpus = 1)\n",
    "                2. label 'OSCAR_medium_job' (comes with memory = 8 GB, time = 16 hours, cpus = 2)\n",
    "                3. label 'OSCAR_large_job' (comes with memory = 16 GB, time = 24 hours, cpus = 2)\n",
    "                \n",
    "\n",
    "README:\n",
    "\n",
    "Please see https://github.com/compbiocore/workflows_on_OSCAR for further details on how to add the above label options to your workflow.\n",
    "\n",
    "Note the setup is designed such that pipelines downloaded from nf-core with their own resource specs within the .nf script will override your defaults.\n",
    "\n",
    "To run Nextflow commands, you must first type and run the nextflow_start command.\n",
    "\n",
    "To further learn how to easily run your Nextflow pipelines on OSCAR, use the Nextflow template shell script located in your ~/nextflow_setup directory.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b4c1e",
   "metadata": {},
   "source": [
    "### Step 4: Selecting An nf-core Pipeline\n",
    "\n",
    "nf-core has many analysis pipelines we can use and so we need to identify the specific pipeline that is appropriate for our needs. We are once again using the RRBS example that we started with, so we need a pipeline that is appropriate to use for processing RRBS data. Heading over to https://nf-co.re/pipelines we can see that the **methylseq** pipeline will work for our data. We can view the details of this pipeline, such as all of its arguments and the steps it performs, by cliking on its link or visiting here: https://nf-co.re/methylseq \n",
    "\n",
    "**Note:** Visitng the pipeline's page and reviewing the pipeline's documentation is important because we need to know what arguments to use to make it run correctly. Once we've reviewed this and got an idea of how we need to run things, we can move to the final step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7759bb0",
   "metadata": {},
   "source": [
    "#### Step 4a. Running methylSeq\n",
    "\n",
    "We want to take advantage of the fact that virtually of the `nf-core` have a test workflow that we can play with; with pre-set inputs and samplesheet pre-sets that we can explore and re-use later as templates to launch our real runs with.  \n",
    "\n",
    "\n",
    "```bash\n",
    "nextflow run nf-core/methylseq -profile test,singularity --outdir methylseq_out\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/UGXkZAZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e30aa6",
   "metadata": {},
   "source": [
    "#### Step 4b. Inspecting the Exact Commands Run:\n",
    "\n",
    "The `conf/test.config` will give you all the parameters/inputs in: https://github.com/nf-core/methylseq/blob/master/conf/test.config: \n",
    "```\n",
    " // Input data\n",
    "    input = \"$test_data_base/samplesheet/samplesheet_test.csv\"\n",
    "\n",
    "    // Genome references\n",
    "    fasta = \"$test_data_base/reference/genome.fa\"\n",
    "    fasta_index = \"$test_data_base/reference/genome.fa.fai\"\n",
    "```\n",
    "\n",
    "https://github.com/nf-core/test-datasets/tree/methylseq/samplesheet/samplesheet_test.csv:\n",
    "![](https://i.imgur.com/JHFvh3B.png)\n",
    "\n",
    "```bash\n",
    "#curl these files so we can use the command and original inputs locally as templates to run our workflow\n",
    "wget https://github.com/nf-core/test-datasets/tree/methylseq/samplesheet/samplesheet_test.csv\n",
    "wget https://github.com/nf-core/test-datasets/tree/methylseq/reference/genome.fa\n",
    "wget https://github.com/nf-core/test-datasets/tree/methylseq/reference/genome.fa.fai\n",
    "\n",
    "nextflow run nf-core/methylseq --input samplesheet_test.csv --fasta genome.fa --fasta_index genome.fa.fai --outdir methylseq_out2\n",
    "```\n",
    "\n",
    "\n",
    "We also can rely on the nf-core's own documentation of what each parameters mean. They are all very documented.\n",
    "\n",
    "Take a look here: https://nf-co.re/methylseq/2.3.0/parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7347e511",
   "metadata": {},
   "source": [
    "#### Step 4c. Once finished, inspecting the Test Workflow Results at `$OUT_DIR/pipeline_info`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf0627",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/bG7Yh8e.png)\n",
    "\n",
    "\n",
    "Inspect the full result here: https://nf-co.re/methylseq/results#methylseq/results-93bc5811603c287c766a0ff7e03b5b41f4483895/bismark/pipeline_info/pipeline_dag_2022-12-17_00-46-10.html:\n",
    "\n",
    "##### Audit Log of Every Step (with Command):\n",
    "![](https://i.imgur.com/qdJw4qT.png)\n",
    "\n",
    "\n",
    "##### Trace Log: \n",
    "![](https://i.imgur.com/YsjYMNe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738df7d",
   "metadata": {},
   "source": [
    "#### Step 4d. Adapt only a task from `nf-core/methylseq`\n",
    "\n",
    "Suppose you like `methylseq` but you would like to adapt, customize or incorporate one of the tasks in your own script; leveraging `nf-core`'s configuration.\n",
    "\n",
    "We will try to this with the `bismark`.\n",
    "\n",
    "We can find where all of the Nextflow processes are defined in `nf-core`'s `modules/nf-core/$PROCESS`;\n",
    "\n",
    "##### https://github.com/nf-core/methylseq/blob/master/modules/nf-core/bismark/align/main.nf:\n",
    "\n",
    "```bash\n",
    "process BISMARK_ALIGN {\n",
    "    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n",
    "        'https://depot.galaxyproject.org/singularity/bismark:0.24.0--hdfd78af_0' :\n",
    "        'quay.io/biocontainers/bismark:0.24.0--hdfd78af_0' }\"\n",
    "    \n",
    "    \"\"\"\n",
    "    bismark \\\\\n",
    "        $fastq \\\\\n",
    "        --genome $index \\\\\n",
    "        --bam \\\\\n",
    "        $args\n",
    "    cat <<-END_VERSIONS > versions.yml\n",
    "    \"${task.process}\":\n",
    "        bismark: \\$(echo \\$(bismark -v 2>&1) | sed 's/^.*Bismark Version: v//; s/Copyright.*\\$//')\n",
    "    END_VERSIONS\n",
    "    \"\"\"\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b90b5",
   "metadata": {},
   "source": [
    "We can simply adapt this task into our toy workflow:\n",
    "\n",
    "#### bismark_copycat.nf:\n",
    "\n",
    "```bash\n",
    "process BISMARK_ALIGN {\n",
    "    container 'https://depot.galaxyproject.org/singularity/bismark:0.24.0--hdfd78af_0'\n",
    "    \n",
    "    output:\n",
    "     stdout\n",
    "    \n",
    "    script:\n",
    "    \"\"\"\n",
    "    bismark #to-do need to wire in the input; but leverage the pre-built container from nf-core\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "  BISMARK_ALIGN() | view\n",
    "}\n",
    "```\n",
    "\n",
    "#### run bismark_copycat.nf:\n",
    "\n",
    "```bash\n",
    "nextflow run bismark_copycat.nf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a70d0e",
   "metadata": {},
   "source": [
    "#### Step 5. Building Your Own Docker Container\n",
    "\n",
    "You don't have to rely only on pre-built containers; and can even build your own containers either from scratch or on top of existing containers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930b9ce",
   "metadata": {},
   "source": [
    "##### Install `salmon` to bismark container\n",
    "\n",
    "###### salmon_Dockerfile:\n",
    "```bash\n",
    "FROM debian:bullseye-slim\n",
    "\n",
    "RUN apt-get update && apt-get install -y curl cowsay\n",
    "RUN curl -sSL https://github.com/COMBINE-lab/salmon/releases/download/v1.5.2/salmon-1.5.2_linux_x86_64.tar.gz | tar xz \\\n",
    "&& mv /salmon-*/bin/* /usr/bin/ \\\n",
    "&& mv /salmon-*/lib/* /usr/lib/\n",
    "```\n",
    "\n",
    "###### Build the Docker (targetting `linux/amd64` for OSCAR and tagged as `salmon:latest`):\n",
    "```bash\n",
    "docker build -f salmon_Dockerfile -t salmon:latest --platform linux/amd64 .\n",
    "```\n",
    "\n",
    "###### Upload to Your DockerHub:\n",
    "```bash\n",
    "docker tag salmon:latest $DOCKER_USER/salmon:latest\n",
    "docker push $DOCKER_USER/salmon:latest\n",
    "```\n",
    "\n",
    "###### Example Output:\n",
    "![](https://i.imgur.com/OYPbYSs.png)\n",
    "\n",
    "###### salmon.nf:\n",
    "\n",
    "```bash\n",
    "process salmon {\n",
    "    container 'cowmoo/salmon:latest'\n",
    "\n",
    "    output:\n",
    "     stdout\n",
    "\n",
    "    script:\n",
    "    \"\"\"\n",
    "    salmon -h\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "  salmon() | view\n",
    "}\n",
    "```\n",
    "\n",
    "###### run salmon.nf:\n",
    "\n",
    "```bash\n",
    "nextflow run salmon.nf\n",
    "```\n",
    "\n",
    "![](https://i.imgur.com/Zt5iMci.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefce1f",
   "metadata": {},
   "source": [
    "## Additional Nextflow Patterns:\n",
    "\n",
    "- Conditionals: https://github.com/stevekm/nextflow-demos/blob/master/conditional-execution/main.nf#L53 (Demonstration you can put in if/switch statements in your tasks)\n",
    "\n",
    "\n",
    "- Making a Samplesheet: https://github.com/stevekm/nextflow-demos/blob/master/parse-samplesheet/main.nf\n",
    " - See the samplesheet:\n",
    "https://github.com/stevekm/nextflow-demos/blob/master/parse-samplesheet/samples.analysis.tsv\n",
    " - See how a samplesheet `Channel` is created: https://github.com/stevekm/nextflow-demos/blob/master/parse-samplesheet/main.nf#L3\n",
    " - See how a downstream task consumes each row (representing the sample) from the original samplesheet: https://github.com/stevekm/nextflow-demos/blob/master/parse-samplesheet/main.nf#L40\n",
    "\n",
    "\n",
    "- More Patterns Here: https://github.com/nextflow-io/patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7259fc",
   "metadata": {},
   "source": [
    "## Tutorial: Using workflow management tools on OSCAR \n",
    "\n",
    "Workflow management tools are software that allow you to write more efficient, portable computational pipelines. As a result, you are able to optimize your workflows while maintaining reproducibility and rigor. Note that there are many workflow management tools available to researchers, but the two tools we will focus on learning about today are **Snakemake** and **Nextflow**. Let's first start with Snakemake..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf3190",
   "metadata": {},
   "source": [
    "<img src=\"./img/snakemake.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece25d38",
   "metadata": {},
   "source": [
    "### Step 1: The Setup\n",
    "\n",
    "Let's first discuss setting up our environment on OSCAR so that we can get Snakemake up and running. \n",
    "\n",
    "**At this point, I am going to open my terminal on Open OnDemand (OOD) so that I can walk you through and show you how each of these steps and files below look. Feel free to open your terminal as well and follow along. To do so, you can go to OOD at https://ood.ccv.brown.edu and under the Clusters tab at the top select the >_OSCAR Shell Access option. All files used today can be found on OSCAR in the folder at: /gpfs/data/shared/bootcamp_2022**\n",
    "\n",
    "Once you are on OSCAR, there are a few ways to run Snakemake. For example, one could set up Snakemake through Conda environments or you could use singularity containers. The details of these tools (i.e., Conda environments and singularity containers) are beyond the scope of this workshop, but here are some helpful links to get you started learning more about these tools, should you be interested: \n",
    "\n",
    "<u>Conda and Conda environments:</u> \n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/environments.html <br>\n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html <br>\n",
    "\n",
    "\n",
    "<u> Singularity containers: </u> \n",
    "\n",
    "https://sylabs.io/guides/3.5/user-guide/introduction.html <br>\n",
    "\n",
    "https://blogs.iu.edu/ncgas/2021/04/29/a-quick-intro-to-singularity-containers/ <br>\n",
    "\n",
    "\n",
    "For this workshop, the specific approach we are going to take is to set up a Python virtual environment (essentially just an isolated environment containing the few pieces of software we need to get up and running) and then within this environment we tell Snakemake to download and run specific pre-built singularity containers for each of the different data processing steps (known as Snakemake rules). Singularity containers are just computer programs a.k.a virtual machines that encapsulate all the software needed for a workflow and thus enable reproducibility. They are widely used on HPC systems because of their increased security relative to other software options.\n",
    "\n",
    "So now let's get started with our set up. First, ssh into OSCAR and wherever you like (and have enough space for storage) create a folder called **snakemake**. To do this, simply type ```mkdir snakemake```. \n",
    "\n",
    "Now enter this folder using ```cd /path/to/snakemake``` and inside it we will set up our virtual environment so that we can have access to and run Snakemake software on OSCAR. To set up our virtual environment, we use the following script: \n",
    "\n",
    "<br> \n",
    "\n",
    "```\n",
    "module load python/3.9.0    # load version of Python needed \n",
    "virtualenv snakemake_env     # create environment \n",
    "source snakemake_env/bin/activate    # activate environment\n",
    "pip3 install snakemake    # install snakemake using pip\n",
    "deactivate    # deactivate and exit, we will use again later!\n",
    "```\n",
    "    \n",
    "**Note:** Save and run this script in your snakemake folder using ```bash env.sh```. This will create a snakemake_env folder in your project directory. \n",
    "\n",
    "After this code has been run, you can now at any point type ```source /path/to/environment/environment_folder_name/bin/activate``` and you will enter an environment that has snakemake software installed and ready to be called for use. Now let's move onto setting up the specific pieces of input that Snakemake needs to run on OSCAR, our HPC cluster. \n",
    "\n",
    "### Step 2: Creating the Snakefile \n",
    "\n",
    "To start using Snakemake on any platform, the first thing one must do is create a **Snakefile**. A Snakefile is a file that defines a Snakemake workflow in terms of rules that are to be carried out in a specific order to complete a pipeline. This file determines the entire flow of your data analysis pipeline, specifying the rules to be carried out and their respective inputs and outputs. We can name this file whatever we like, as long as we tell our Snakemake program where to find it; however, by convention, we usually name this file Snakefile (with no extension!). \n",
    "\n",
    "I create a file called Snakefile and store this file in my newly created **snakemake** folder. Drawing on the same RRBS example we started with, the Snakefile would be: \n",
    "\n",
    "**Snakefile**\n",
    "\n",
    "```python\n",
    "## Snakefile for BootCamp ##\n",
    "\n",
    "# Specify configuration file to use - optional\n",
    "# configfile: \"/path/to/file/config.yaml\"\n",
    "\n",
    "# Define sample to iterate across data \n",
    "sample=[\"sample_1\", \"sample_2\", \"sample_3\", \"sample_4\"]\n",
    "\n",
    "# Create rules\n",
    "rule all:\n",
    "    message: \"All done....!\"\n",
    "    input:\n",
    "        expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_trimmed.fq.gz\", sample=sample),\n",
    "        expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}.fastq.gz_trimming_report.txt\", sample=sample),\n",
    "        expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_bismark_bt2_pe.bam\", sample=sample),\n",
    "        expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_bismark_bt2_PE_report.txt\", sample=sample),\n",
    "        expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_bismark_bt2_pe.nucleotide_stats.txt\", sample=sample)\n",
    "\n",
    "\n",
    "rule fastqc:\n",
    "    message: \"Running FastQC...\"\n",
    "    input:\n",
    "        rawread=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/data_new/{sample}.fq.gz\", sample=sample) \n",
    "    output:\n",
    "        zip=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/fastqc/{sample}.zip\", sample=sample), \n",
    "        html=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/fastqc/{sample}.html\", sample=sample)\n",
    "    singularity: \"library://ftabaro/default/methylsnake\" \n",
    "    shell: \"fastqc {input.rawread} -o /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/fastqc\"\n",
    "\n",
    "rule trim:\n",
    "   message: \"Performing reads trimming...\" \n",
    "   input:\n",
    "       rawreads=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/data_new/{sample}.fq.gz\", sample=sample)\n",
    "   output:\n",
    "       trimmed=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_trimmed.fq.gz\", sample=sample),\n",
    "       report=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}.fastq.gz_trimming_report.txt\", sample=sample)\n",
    "   params:  \n",
    "     quality_filter_value=\"22\",\n",
    "   threads: 4\n",
    "   singularity: \"library://ftabaro/default/methylsnake\"\n",
    "   shell: \"trim_galore --quality {params.quality_filter_value} --phred33 --output_dir /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim --gzip --rrbs --fastqc --cores {threads} {input.rawreads}\" \n",
    "\n",
    "rule bismark_align:\n",
    "    message: \"Performing alignment...\"\n",
    "    input:\n",
    "        trimreads=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_trimmed.fq.gz\", sample=sample)\n",
    "    output: \n",
    "      bam=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_bismark_bt2_pe.bam\", sample=sample),\n",
    "      bisreport=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_bismark_bt2_PE_report.txt\", sample=sample),\n",
    "      stats=expand(\"/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/trim/{sample}_bismark_bt2_pe.nucleotide_stats.txt\", sample=sample)\n",
    "    threads: 4\n",
    "    singularity: \"library://ftabaro/default/methylsnake\"\n",
    "    shell: \"bismark -o /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/alignment --bowtie2 --genome /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/index --un --pbat {input.trimreads}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad8e88",
   "metadata": {},
   "source": [
    "### Step 3: Telling Snakemake how to run on the HPC Cluster  \n",
    "\n",
    "After defining the rules and analysis steps for our workflow via the Snakefile, we now must set up the workflow to be compatible with our HPC cluster, telling it how to assign resources to each rule. This is done by creating a yaml file called **cluster.yaml** (really it can be called anything, as long as the extension is .yaml). This file can be stored anywhere, as long as you specify where it can be found by the Snakemake program when it's run (will see this later). But for simplicity, it's best to just create and save it in the same place as your Snakefile. We specify the cluster.yaml file as follows: \n",
    "\n",
    "**cluster.yaml**\n",
    "\n",
    "```yaml\n",
    "__default__:\n",
    "  partition: \"batch\"\n",
    "  cpus: \"1\"\n",
    "  time: 60\n",
    "  mem: \"4g\"\n",
    "  email: jordan_lawson@brown.edu  \n",
    "  email_type: \"ALL\"\n",
    "```\n",
    "\n",
    "In the above, we create a default specification, where each rule, by default, will get this resource allocation when run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da9821",
   "metadata": {},
   "source": [
    "### Step 4: Bringing it all together with Shell Scripting \n",
    "\n",
    "Now here is the step where we tie everything together, running our Snakefile and cluster specification all with one script, a shell script. To run everything on OSCAR, we can use the following script: \n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "##############################\n",
    "#                             # \n",
    "#       Snakemake             #\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "##### 1.) Job Sumbission Options ######\n",
    "\n",
    "# Change these as needed \n",
    "\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH -n 2\n",
    "#SBATCH -J snake_test\n",
    "#SBATCH --mem=16GB\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=jordan_lawson@brown.edu\n",
    "\n",
    "###### 2.) Run snakemake #####\n",
    "\n",
    "# Activate virtual environment \n",
    "source snakemake_env/bin/activate\n",
    "\n",
    "# Run snakemake - note you will need a cluster.yaml file as this command references one!\n",
    "snakemake --use-singularity --singularity-args \"-B /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/:/gpfs/data/ccvstaff/jlawson9/bootcamp_2022/\" -s /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/Snakefile --cluster-config /gpfs/data/ccvstaff/jlawson9/bootcamp_2022/snakemake/cluster.yaml --latency-wait 60 --cluster 'sbatch -t {cluster.time} --mem={cluster.mem} -c {cluster.cpus} --mail-type {cluster.email_type} --mail-user {cluster.email}' -j 10\n",
    "```\n",
    "\n",
    "I save this script as **snakemake.sh** and place it in the snakemake folder with the other files I recently created. Once we have this with everything else, we can run everything on the cluster by typing ```sbatch snakemake.sh```\n",
    "\n",
    "Note in the above that we are running the snakemake program with the Snakefile and cluster.yaml files we specified. Some other important things: \n",
    "\n",
    "- your log file for slurm will automtatically be placed in the same directory that you ran the snakemake.sh script from. However, you can also get more detailed log files for each snakemake rule and its respective outputs by using the ```log:``` command followed by the path you want the logs files to go to in each of the rules found within the Snakefile \n",
    "\n",
    "- we are using the --use-singularity argument in the above shell script to allow for Snakemake to use a singularity container when running pipelines; this is highly recommended for reproducibility. \n",
    "\n",
    "- when using the singularity argument, **it is very, very important** that you include the ```--singularity-args \"-B folder_to_mount:source_destination\"``` argument or else your pipeline will fail to recognize any inputs and outputs you are specifying in the workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe43b14",
   "metadata": {},
   "source": [
    "## A Few Closing Thoughts.....\n",
    "\n",
    "This workshop just provided an introductory overview of running worklfow management tools on OSCAR. There is much more customization that you can do and much more advanced things you can perform. Some of these are: \n",
    "\n",
    "* Resource allocation by rule (or analysis step) \n",
    "* Using a config.yaml file to handle your samples and how you iterate through files\n",
    "* Running pipelines that skip steps and start at a specific step (for example, pipelines that fail at a certain step, you may not want to repeat everything but instead pick up where you left off)\n",
    "* Handling log files within specific steps so that you get detailed output for each rule \n",
    "* And much more...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
